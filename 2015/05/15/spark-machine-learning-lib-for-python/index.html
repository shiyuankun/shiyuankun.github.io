<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>spark machine learning lib for python | 彼格海德的笔记空间</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="今天看了一下pyspark的mllib这个库。作为一个大数据计算平台，spark这点比hadoop向前走了一大步。提供了种类繁多的数据计算的模型，从随机数生成到线性代数到回归聚类。粗粗的看了一下，pyspark在做这个mllib的时候实现有两种，一种是spark原生型的api调用，比如刚才提到的回归聚类，都是直接输入rdd然后不断迭代返回结果，比如
class LogisticRegression">
<meta property="og:type" content="article">
<meta property="og:title" content="spark machine learning lib for python">
<meta property="og:url" content="http://yoursite.com/2015/05/15/spark-machine-learning-lib-for-python/index.html">
<meta property="og:site_name" content="彼格海德的笔记空间">
<meta property="og:description" content="今天看了一下pyspark的mllib这个库。作为一个大数据计算平台，spark这点比hadoop向前走了一大步。提供了种类繁多的数据计算的模型，从随机数生成到线性代数到回归聚类。粗粗的看了一下，pyspark在做这个mllib的时候实现有两种，一种是spark原生型的api调用，比如刚才提到的回归聚类，都是直接输入rdd然后不断迭代返回结果，比如
class LogisticRegression">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="spark machine learning lib for python">
<meta name="twitter:description" content="今天看了一下pyspark的mllib这个库。作为一个大数据计算平台，spark这点比hadoop向前走了一大步。提供了种类繁多的数据计算的模型，从随机数生成到线性代数到回归聚类。粗粗的看了一下，pyspark在做这个mllib的时候实现有两种，一种是spark原生型的api调用，比如刚才提到的回归聚类，都是直接输入rdd然后不断迭代返回结果，比如
class LogisticRegression">
  
    <link rel="alternative" href="/atom.xml" title="彼格海德的笔记空间" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-62861406-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->


  
<!-- Baidu Statistics -->
<script type="text/javascript">
    var _hmt = _hmt || [];
(function() {
 var hm = document.createElement("script");
 hm.src = "//hm.baidu.com/hm.js?77faa6f8da10ec42fb1c01f2947de873";
 var s = document.getElementsByTagName("script")[0]; 
 s.parentNode.insertBefore(hm, s);
 })();
</script>
<!-- End Baidu Statistics -->


</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">彼格海德的笔记空间</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">a notebook for python</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/about/index.html">About</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="q" value="site:http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-spark-machine-learning-lib-for-python" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/05/15/spark-machine-learning-lib-for-python/" class="article-date">
  <time datetime="2015-05-15T05:29:26.000Z" itemprop="datePublished">2015-05-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      spark machine learning lib for python
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>今天看了一下pyspark的mllib这个库。作为一个大数据计算平台，spark这点比hadoop向前走了一大步。提供了种类繁多的数据计算的模型，从随机数生成到线性代数到回归聚类。<br>粗粗的看了一下，pyspark在做这个mllib的时候实现有两种，一种是spark原生型的api调用，比如刚才提到的回归聚类，都是直接输入rdd然后不断迭代返回结果，比如</p>
<pre><code><span class="class"><span class="keyword">class</span> <span class="title">LogisticRegressionWithSGD</span><span class="params">(object)</span>:</span>

    <span class="decorator">@classmethod</span>
    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(cls, data, iterations=<span class="number">100</span>, step=<span class="number">1.0</span>, miniBatchFraction=<span class="number">1.0</span>,
              initialWeights=None, regParam=<span class="number">0.01</span>, regType=<span class="string">"l2"</span>, intercept=False)</span>:</span>
        <span class="string">"""
        Train a logistic regression model on the given data.

        :param data:              The training data, an RDD of LabeledPoint.
        :param iterations:        The number of iterations (default: 100).
        :param step:              The step parameter used in SGD
                                  (default: 1.0).
        :param miniBatchFraction: Fraction of data to be used for each SGD
                                  iteration.
        :param initialWeights:    The initial weights (default: None).
        :param regParam:          The regularizer parameter (default: 0.01).
        :param regType:           The type of regularizer used for training
                                  our model.

                                  :Allowed values:
                                     - "l1" for using L1 regularization
                                     - "l2" for using L2 regularization
                                     - None for no regularization

                                     (default: "l2")

        :param intercept:         Boolean parameter which indicates the use
                                  or not of the augmented representation for
                                  training data (i.e. whether bias features
                                  are activated or not).
        """</span>
        <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(rdd, i)</span>:</span>
            <span class="keyword">return</span> callMLlibFunc(<span class="string">"trainLogisticRegressionModelWithSGD"</span>, rdd, int(iterations),
                                 float(step), float(miniBatchFraction), i, float(regParam), regType,
                                 bool(intercept))

        <span class="keyword">return</span> _regression_train_wrapper(train, LogisticRegressionModel, data, initialWeights)


<span class="function"><span class="keyword">def</span> <span class="title">callMLlibFunc</span><span class="params">(name, *args)</span>:</span>
    <span class="string">""" Call API in PythonMLLibAPI """</span>
    sc = SparkContext._active_spark_context
    api = getattr(sc._jvm.PythonMLLibAPI(), name)
    <span class="keyword">return</span> callJavaFunc(sc, api, *args)
</code></pre><p>第一类api全都把工作丢给了spark去做，也就是其实是跨节点并行计算。<br>第二类api就比较奇怪了，linalg里面全是这类函数，如</p>
<pre><code><span class="class"><span class="keyword">class</span> <span class="title">DenseVector</span><span class="params">(Vector)</span>:</span>
    <span class="string">"""
    A dense vector represented by a value array. We use numpy array for
    storage and arithmetics will be delegated to the underlying numpy
    array.

    def dot(self, other):
        """</span>
        Compute the dot product of two Vectors. We support
        (Numpy array, list, SparseVector, <span class="keyword">or</span> SciPy sparse)
        <span class="keyword">and</span> a target NumPy array that <span class="keyword">is</span> either <span class="number">1</span>- <span class="keyword">or</span> <span class="number">2</span>-dimensional.
        Equivalent to calling numpy.dot of the two vectors.
        <span class="keyword">if</span> type(other) == np.ndarray:
            <span class="keyword">if</span> other.ndim &gt; <span class="number">1</span>:
                <span class="keyword">assert</span> len(self) == other.shape[<span class="number">0</span>], <span class="string">"dimension mismatch"</span>
            <span class="keyword">return</span> np.dot(self.array, other)
        <span class="keyword">elif</span> _have_scipy <span class="keyword">and</span> scipy.sparse.issparse(other):
            <span class="keyword">assert</span> len(self) == other.shape[<span class="number">0</span>], <span class="string">"dimension mismatch"</span>
            <span class="keyword">return</span> other.transpose().dot(self.toArray())
        <span class="keyword">else</span>:
            <span class="keyword">assert</span> len(self) == _vector_size(other), <span class="string">"dimension mismatch"</span>
            <span class="keyword">if</span> isinstance(other, SparseVector):
                <span class="keyword">return</span> other.dot(self)
            <span class="keyword">elif</span> isinstance(other, Vector):
                <span class="keyword">return</span> np.dot(self.toArray(), other.toArray())
            <span class="keyword">else</span>:
                <span class="keyword">return</span> np.dot(self.toArray(), other)
</code></pre><p>居然全部都是丢给numpy去做，虽然numpy做这类计算的效率很高不假但这样就没有spark的跨节点并行的优势了，在计算的时候要注意。另外听说spark的运行效率首先于带宽，根据我有限的hpc经验来看，网络的延迟影响可能也会很大。而spark所在的网络最多也就是万兆网络，在做矩阵并行计算这类对网络延迟依赖很大的计算的时候可能会很慢，开发人员会不会因此考虑将不少矩阵计算本地化呢？不得而知，我很好奇下一个版本如果他们给出矩阵求逆以及对焦化或者svd是不是依然也使用本地计算。如果这个问题不解决可能对spark要称霸大数据平台有点影响。</p>
<p>好了，pyspark的代码看的差不多了，接下去就是用scala写的spark了，cross fingers</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/05/15/spark-machine-learning-lib-for-python/" data-id="cib610iue000qyjv4zlrx98mz" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/mllib/">mllib</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/">python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/spark/">spark</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2015/05/15/explore-spark-RDD-source-code/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          expore spark RDD source code
        
      </div>
    </a>
  
  
    <a href="/2015/05/14/explore-the-source-of-pyspark-dataframe/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">pyspark dataframe的实现</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/RDD/">RDD</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/benchmark/">benchmark</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/blog/">blog</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cnblogs/">cnblogs</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cython/">cython</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/dataframe/">dataframe</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/f2py/">f2py</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/github/">github</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hexo/">hexo</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/migrate/">migrate</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mllib/">mllib</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/numba/">numba</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/numpy/">numpy</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pyspark/">pyspark</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/rdd/">rdd</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scala/">scala</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scheduler/">scheduler</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spark/">spark</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/task/">task</a><span class="tag-list-count">1</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/RDD/" style="font-size: 10px;">RDD</a><a href="/tags/benchmark/" style="font-size: 10px;">benchmark</a><a href="/tags/blog/" style="font-size: 12.5px;">blog</a><a href="/tags/cnblogs/" style="font-size: 10px;">cnblogs</a><a href="/tags/cython/" style="font-size: 10px;">cython</a><a href="/tags/dataframe/" style="font-size: 10px;">dataframe</a><a href="/tags/f2py/" style="font-size: 10px;">f2py</a><a href="/tags/github/" style="font-size: 10px;">github</a><a href="/tags/hexo/" style="font-size: 12.5px;">hexo</a><a href="/tags/migrate/" style="font-size: 10px;">migrate</a><a href="/tags/mllib/" style="font-size: 12.5px;">mllib</a><a href="/tags/numba/" style="font-size: 10px;">numba</a><a href="/tags/numpy/" style="font-size: 10px;">numpy</a><a href="/tags/pyspark/" style="font-size: 10px;">pyspark</a><a href="/tags/python/" style="font-size: 17.5px;">python</a><a href="/tags/rdd/" style="font-size: 10px;">rdd</a><a href="/tags/scala/" style="font-size: 15px;">scala</a><a href="/tags/scheduler/" style="font-size: 10px;">scheduler</a><a href="/tags/spark/" style="font-size: 20px;">spark</a><a href="/tags/task/" style="font-size: 10px;">task</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/06/">June 2015</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/05/">May 2015</a><span class="archive-list-count">10</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/04/">April 2015</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/01/">January 2015</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/09/">September 2014</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/06/">June 2014</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/12/">December 2013</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/11/">November 2013</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/10/">October 2013</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/09/">September 2013</a><span class="archive-list-count">5</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/08/">August 2013</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/04/">April 2013</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2012/06/">June 2012</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2012/04/">April 2012</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2012/03/">March 2012</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2012/01/">January 2012</a><span class="archive-list-count">4</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2015/06/21/explore-spark-distributed-mllib/">spark的mllib到底是不是分布式的</a>
          </li>
        
          <li>
            <a href="/2015/06/09/spark-task-and-scheduler/">spark 的调度和任务</a>
          </li>
        
          <li>
            <a href="/2015/05/15/explore-spark-RDD-source-code/">expore spark RDD source code</a>
          </li>
        
          <li>
            <a href="/2015/05/15/spark-machine-learning-lib-for-python/">spark machine learning lib for python</a>
          </li>
        
          <li>
            <a href="/2015/05/14/explore-the-source-of-pyspark-dataframe/">pyspark dataframe的实现</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2015 Yuankun Shi<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/about/index.html" class="mobile-nav-link">About</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>


<script src="/js/script.js" type="text/javascript"></script>

  </div>
</body>
</html>